###############################################################################
# Plexus Configuration Documentation
###############################################################################
#
# This file configures the Plexus 2 gateway, defining how requests are routed
# and transformed between different LLM providers.
#
# 1. PROVIDERS SECTION
# --------------------
# Define your upstream AI providers here.
#
#   display_name: A friendly name for logging and metadata.
#   api_base_url: The root endpoint for the provider's API.
#                 Plexus automatically infers the API type (chat/messages/gemini) from this URL:
#                 - URLs containing 'anthropic.com' are treated as 'messages' (Anthropic format)
#                 - URLs containing 'generativelanguage.googleapis.com' are treated as 'gemini'
#                 - All other URLs default to 'chat' (OpenAI-compatible format)
#
#                 For providers that support multiple formats, use a map:
#                 api_base_url:
#                   chat: https://api.example.com/v1
#                   messages: https://api.example.com/anthropic/v1
#
#   api_key:      Your authentication token for the provider (required).
#   models:       A list of raw model identifiers supported by this provider.
#                 OR a map of model names to configuration (e.g. pricing).
#   headers:      (Optional) Custom HTTP headers to include in every request.
#
# 2. MODELS SECTION (ALIASES)
# ---------------------------
# Define friendly "Model Aliases" that your clients will use.
#
#   selector:     (Optional) The strategy to select a target.
#                 Options: 'random' (default), 'cost', 'performance', 'latency', 'in_order'.
#                 If multiple targets are available, Plexus will prioritize
#                 selection based on the defined 'selector'.
#                   - random: Randomly selects a healthy target.
#                   - in_order: Selects providers in the order defined. Falls back to next if current is unhealthy.
#                   - cost: Selects the target with the lowest configured cost.
#                   - performance: Selects the target with the highest average tokens/sec.
#                   - latency: Selects the target with the lowest average time-to-first-token.
#
# 3. KEYS SECTION
# ---------------
# Define valid API keys for accessing the Plexus gateway.
#
#   secret:       The actual bearer token string clients must provide.
#   comment:      (Optional) Description or owner of the key.
#
###############################################################################

# [REQUIRED] Admin Key for Dashboard and Management API Access
adminKey: "change-me-to-a-secure-admin-password"

providers:
  # Standard OpenAI Configuration
  # API type is automatically inferred as 'chat' from the URL
  openai:
    display_name: OpenAI
    api_base_url: https://api.openai.com/v1
    api_key: "your-openai-api-key-here"
    models:
      - gpt-4o
      - gpt-4o-mini
      - o1-preview

  # Standard Anthropic Configuration
  # API type is automatically inferred as 'messages' from the URL
  anthropic:
    display_name: Anthropic Claude
    api_base_url: https://api.anthropic.com/v1
    api_key: "your-anthropic-api-key-here"
    models:
      - claude-3-5-sonnet-latest
      - claude-3-5-haiku-latest
      - claude-3-opus-latest

  # Standard Google Gemini Configuration
  # API type is automatically inferred as 'gemini' from the URL
  gemini:
    display_name: Google Gemini
    api_base_url: https://generativelanguage.googleapis.com
    api_key: "your-gemini-api-key-here"
    models:
      - gemini-1.5-pro
      - gemini-1.5-flash
      - gemini-2.0-flash-exp

  # Example with Pricing Configuration
  # Pricing is per 1M tokens.
  openai_cost_tracked:
    display_name: OpenAI (Tracked)
    api_base_url: https://api.openai.com/v1
    api_key: "your-openai-api-key-here"
    models:
      gpt-4o:
        pricing:
          source: simple
          input: 2.50
          output: 10.00
      gpt-4o-mini:
        pricing:
          source: simple
          input: 0.15
          output: 0.60

  # Example with Tiered Pricing Configuration (Defined Strategy)
  # Pricing changes based on input token usage volume.
  tiered_pricing_example:
    display_name: Tiered Pricing Provider
    api_base_url: https://api.example.com/v1
    api_key: "your-api-key"
    models:
      tiered-model-v1:
        pricing:
          source: defined
          range:
            # Tier 1: 0 - 1M tokens
            - lower_bound: 0
              upper_bound: 1000000
              input_per_m: 5.00
              output_per_m: 15.00
            # Tier 2: > 1M tokens
            - lower_bound: 1000001
              upper_bound: .inf
              input_per_m: 4.00
              output_per_m: 12.00

  # Example of a Chat-compatible provider (e.g. Together, DeepSeek, Groq)
  # API type is automatically inferred as 'chat'
  deepseek:
    display_name: DeepSeek
    api_base_url: https://api.deepseek.com
    api_key: "your-deepseek-api-key-here"
    models:
      - deepseek-chat
      - deepseek-reasoner

  # Example of a multi-protocol provider
  # This provider supports both OpenAI (chat) and Anthropic (messages) formats
  # Use a map to specify different URLs for each format
  synthetic:
    display_name: Synthetic Provider
    # Map API types to specific base URLs - types are inferred from the keys
    api_base_url:
      chat: https://api.synthetic.new/openai/v1
      messages: https://api.synthetic.new/messages/v1
    api_key: "your-synthetic-key"
    models:
      # This model can be accessed via both formats
      "hf:MiniMaxAI/MiniMax-M2.1":
        access_via: ["chat", "messages"]
      # This model only supports the messages format
      "legacy-model":
        access_via: ["messages"]

  # Example with custom headers and OpenRouter pricing lookup
  openrouter:
    display_name: OpenRouter
    api_base_url: https://openrouter.ai/api/v1
    api_key: "your-openrouter-key-here"
    # Optional global discount for this provider (e.g., 5% off)
    discount: 0.05
    models:
      google/gemini-pro-1.5:
        pricing:
          source: openrouter
          slug: google/gemini-pro-1.5
      # Example with discount (e.g., 10% off list price)
      anthropic/claude-3.5-sonnet:
        pricing:
          source: openrouter
          slug: anthropic/claude-3.5-sonnet
          discount: 0.1
    headers:
      "HTTP-Referer": "https://your-app.com"
  smart-model:
    targets:
      - provider: anthropic
        model: claude-3-5-sonnet-latest

  # Alias with additional aliases
  # Requests to 'gpt-4' or 'gpt-4-turbo' will also route here
  gpt-4-wrapper:
    additional_aliases:
      - gpt-4
      - gpt-4-turbo
    targets:
      - provider: openai
        model: gpt-4o

  # Alias routing to a Chat-compatible backend
  fast-model:
    targets:
      - provider: openai
        model: gpt-4o-mini

  # Reasoning model alias
  reasoning-model:
    targets:
      - provider: deepseek
        model: deepseek-reasoner

  # Example of Load Balancing with Explicit Selector
  # Requests to 'balanced-model' will distribute randomly across these two targets
  balanced-model:
    selector: random
    # Optional: prioritizing native API matching over the selector
    # If a client sends an Anthropic request, Plexus will prefer the 'anthropic' provider
    priority: api_match
    targets:
      - provider: openai
        model: gpt-4o
      - provider: anthropic
        model: claude-3-5-sonnet-latest

  # Example using Performance Selector (Fastest TPS)
  fastest-throughput-model:
    selector: performance
    targets:
      - provider: groq
        model: llama-3.1-70b
      - provider: openai
        model: gpt-4o-mini

  # Example using Latency Selector (Lowest TTFT)
  lowest-latency-model:
    selector: latency
    targets:
      - provider: anthropic
        model: claude-3-5-haiku-latest
      - provider: openai
        model: gpt-4o-mini

  # Example using InOrder Selector (Defined Order with Fallback)
  # Requests route to 'kilo' first, then 'naga', then 'synthetic' if earlier ones are unavailable
  # Individual targets can be disabled without removing them from the config
  minimax-m2.1:
    selector: in_order
    targets:
      - provider: kilo
        model: minimax/minimax-m2.1
      - provider: naga
        model: minimax-m2.1
      - provider: synthetic
        model: "hf:MiniMaxAI/MiniMax-M2.1"

  # Example with disabled target
  # The first target is disabled, so routing will skip it
  example-with-disabled-target:
    selector: cost
    targets:
      - provider: kilo
        model: minimax/minimax-m2.1
        enabled: false  # This target is temporarily disabled
      - provider: naga
        model: minimax-m2.1
        enabled: true   # Optional: true is the default
      - provider: synthetic
        model: "hf:MiniMaxAI/MiniMax-M2.1"
        # enabled field omitted - defaults to true

  # OAuth Provider Routing Example
  # Route requests to OAuth-authenticated Antigravity accounts
  gemini-thinking:
    targets:
      - provider: my-antigravity
        model: gemini-2.0-flash-thinking-exp

  # Multi-Target with OAuth Provider
  # Load balances between OAuth-enabled Antigravity and API-key OpenAI
  hybrid-smart-model:
    selector: random
    targets:
      - provider: my-antigravity
        model: gemini-2.0-flash-thinking-exp
      - provider: openai
        model: gpt-4o

  # Claude Code OAuth Routing Example
  # Route requests to OAuth-authenticated Claude Code accounts
  claude-sonnet:
    targets:
      - provider: my-claude-code
        model: claude-sonnet-4-5

  # Claude Code with Cost-Based Selection
  # Automatically selects cheapest available Claude model
  claude-smart:
    selector: cost
    targets:
      - provider: my-claude-code
        model: claude-3-5-sonnet-latest
      - provider: my-claude-code
        model: claude-sonnet-4-5

  # Hybrid Multi-Provider with Claude Code OAuth
  # Load balances between OAuth Claude Code and standard Anthropic API key
  claude-hybrid:
    selector: random
    targets:
      - provider: my-claude-code
        model: claude-sonnet-4-5
      - provider: anthropic
        model: claude-3-5-sonnet-latest

keys:
  # Example API Key for accessing Plexus
  my-app-key:
    secret: "sk-plexus-example-key-123"
    comment: "Key for the main application"
  
  # Another key for testing
  test-key:
    secret: "sk-plexus-test-key-456"
    comment: "CI/CD Test Key"